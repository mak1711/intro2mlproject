{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this code we try and load the data pre process it and train it on models that we made from scratch to test their effeciency and what works best."
      ],
      "metadata": {
        "id": "PnDUUuGV8GAD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M3bASvAEgyZ",
        "outputId": "076e63cc-b09a-4d6a-ceb3-a7bd4a7818e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                                               text        label language\n",
            "0                listen will you now give me a show   do_a_trick       en\n",
            "1          hey friend can you instantly flip around  turn_around       en\n",
            "2                  go1 could you quickly posture up        stand       en\n",
            "3              listen go1 can you for me about face  turn_around       en\n",
            "4  listen friend could you now go back about 6 step      go_back       en\n",
            "label\n",
            "do_a_trick     6250\n",
            "turn_around    6250\n",
            "stand          6250\n",
            "go_back        6250\n",
            "go_right       6250\n",
            "go_forward     6250\n",
            "sit            6250\n",
            "go_left        6250\n",
            "no_meaning     6250\n",
            "Name: count, dtype: int64\n",
            "Training samples: 39375\n",
            "Validation samples: 8437\n",
            "Test samples: 8438\n"
          ]
        }
      ],
      "source": [
        "# ==========================\n",
        "# IMPORTS\n",
        "# ==========================\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# ==========================\n",
        "# MOUNT GOOGLE DRIVE\n",
        "# ==========================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ==========================\n",
        "# LOAD DATA\n",
        "# ==========================\n",
        "script_dir = \"/content/drive/MyDrive/data\"\n",
        "file_name = \"voice_commands_dataset_en_with_no_meaning.csv\"\n",
        "file_path = os.path.join(script_dir, file_name)\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "# ==========================\n",
        "# TRAIN/VAL/TEST SPLIT\n",
        "# ==========================\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "# Split into train + temp\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "# Split temp into validation + test\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Validation samples: {len(X_val)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code implements a deep Bi-directional LSTM model for intent classification:\n",
        "\n",
        "Embedding layer: Converts words into 64-dimensional dense vectors.\n",
        "\n",
        "Three BiLSTM layers:\n",
        "\n",
        "128 units, returns sequences → followed by 30% dropout\n",
        "\n",
        "64 units, returns sequences → 30% dropout\n",
        "\n",
        "32 units, returns last output → 30% dropout\n",
        "\n",
        "Dense layers:\n",
        "\n",
        "64-unit fully connected layer with ReLU → 30% dropout\n",
        "\n",
        "Output layer with softmax activation matching the number of intent classes.\n",
        "\n",
        "It is trained using categorical cross-entropy and Adam optimizer, taking sequences of max length 20 as input, and predicts the probability for each intent class.\n",
        "\n",
        "The accuracy it gave was very high from the begining so we change the architecture and retrain since we think it did overfit on the data."
      ],
      "metadata": {
        "id": "YrGgt1eQ8PKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# TOKENIZATION & PADDING\n",
        "# ==========================\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_len = 20  # max words per command, adjust if needed\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "# ==========================\n",
        "# LABEL ENCODING\n",
        "# ==========================\n",
        "le = LabelEncoder()\n",
        "y_train_enc = to_categorical(le.fit_transform(y_train))\n",
        "y_val_enc = to_categorical(le.transform(y_val))\n",
        "y_test_enc = to_categorical(le.transform(y_test))\n",
        "num_classes = y_train_enc.shape[1]\n",
        "\n",
        "# ==========================\n",
        "# BUILD MULTI-LAYER MODEL\n",
        "# ==========================\n",
        "embedding_dim = 64\n",
        "\n",
        "model = Sequential()\n",
        "# Embedding layer\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
        "# First LSTM layer\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(Dropout(0.3))\n",
        "# Second LSTM layer\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.3))\n",
        "# Third LSTM layer\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dropout(0.3))\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# ==========================\n",
        "# TRAIN MODEL\n",
        "# ==========================\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train_enc,\n",
        "    validation_data=(X_val_pad, y_val_enc),\n",
        "    epochs=15,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# ==========================\n",
        "# EVALUATE\n",
        "# ==========================\n",
        "y_pred = model.predict(X_test_pad)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "y_test_classes = y_test_enc.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_test_classes, y_pred_classes, target_names=le.classes_))\n",
        "\n",
        "# ==========================\n",
        "# OPTIONAL: SAVE MODEL\n",
        "# ==========================\n",
        "model.save(\"/content/drive/MyDrive/voice_intent_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iwZVzucnF_Py",
        "outputId": "ed4037bd-da94-4887-c89d-52b7c3fb136c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_10                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_11                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_12                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_10                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_11                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_12                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.6438 - loss: 0.9005 - val_accuracy: 0.9967 - val_loss: 0.0225\n",
            "Epoch 2/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.9920 - loss: 0.0440 - val_accuracy: 0.9998 - val_loss: 0.0027\n",
            "Epoch 3/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.9987 - loss: 0.0065 - val_accuracy: 0.9986 - val_loss: 0.0118\n",
            "Epoch 4/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9965 - loss: 0.0175 - val_accuracy: 0.9998 - val_loss: 4.8702e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 2.4189e-05\n",
            "Epoch 6/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9988 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 4.1779e-05\n",
            "Epoch 7/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 6.1566e-06\n",
            "Epoch 8/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.9999 - loss: 7.0667e-04 - val_accuracy: 1.0000 - val_loss: 8.1396e-07\n",
            "Epoch 9/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.9987 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 1.6420e-06\n",
            "Epoch 10/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 6.6830e-07\n",
            "Epoch 11/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 3.1022e-07\n",
            "Epoch 12/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.7301e-04 - val_accuracy: 1.0000 - val_loss: 2.9501e-08\n",
            "Epoch 13/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.9999 - loss: 1.3597e-04 - val_accuracy: 1.0000 - val_loss: 1.0823e-08\n",
            "Epoch 14/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 4.5375e-05 - val_accuracy: 1.0000 - val_loss: 3.9844e-09\n",
            "Epoch 15/15\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.8447e-05 - val_accuracy: 1.0000 - val_loss: 5.6517e-11\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  do_a_trick       1.00      1.00      1.00       937\n",
            "     go_back       1.00      1.00      1.00       937\n",
            "  go_forward       1.00      1.00      1.00       938\n",
            "     go_left       1.00      1.00      1.00       938\n",
            "    go_right       1.00      1.00      1.00       938\n",
            "  no_meaning       1.00      1.00      1.00       937\n",
            "         sit       1.00      1.00      1.00       938\n",
            "       stand       1.00      1.00      1.00       937\n",
            " turn_around       1.00      1.00      1.00       938\n",
            "\n",
            "    accuracy                           1.00      8438\n",
            "   macro avg       1.00      1.00      1.00      8438\n",
            "weighted avg       1.00      1.00      1.00      8438\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the second model which with a first look is better but still may be overfitting its architecture is as follows:\n",
        "This model is a deep Bi-directional LSTM network for intent classification. It has an embedding layer (64-dim), two BiLSTM layers (64 and 32 units), each followed by dropout, a dense layer with 64 neurons, another dropout, and a softmax output layer that predicts probabilities for each intent class. It uses heavy dropout and spatial dropout for regularization to prevent overfitting."
      ],
      "metadata": {
        "id": "DGnt3OlI8tbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# IMPORTS\n",
        "# ==========================\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, SpatialDropout1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "import random\n",
        "\n",
        "# ==========================\n",
        "# MOUNT DRIVE\n",
        "# ==========================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ==========================\n",
        "# LOAD DATA\n",
        "# ==========================\n",
        "script_dir = \"/content/drive/MyDrive/data\"\n",
        "file_name = \"voice_commands_dataset_en_with_no_meaning.csv\"\n",
        "file_path = os.path.join(script_dir, file_name)\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "# ==========================\n",
        "# SIMPLE DATA AUGMENTATION\n",
        "# ==========================\n",
        "# Replace some words with synonyms (very basic example)\n",
        "synonyms = {\n",
        "    \"stand\": [\"stand up\", \"rise\", \"get up\"],\n",
        "    \"sit\": [\"sit down\", \"take a seat\"],\n",
        "    \"go_forward\": [\"move forward\", \"advance\", \"go ahead\"],\n",
        "    \"go_back\": [\"move back\", \"retreat\", \"go backward\"],\n",
        "    \"go_left\": [\"turn left\", \"move left\"],\n",
        "    \"go_right\": [\"turn right\", \"move right\"],\n",
        "    \"turn_around\": [\"spin\", \"rotate 180\", \"turn\"],\n",
        "    \"do_a_trick\": [\"perform a trick\", \"show a trick\"],\n",
        "    \"no_meaning\": []  # no synonyms (skip)\n",
        "}\n",
        "\n",
        "def augment_command(command, intent):\n",
        "    if intent in synonyms and synonyms[intent]:\n",
        "        if random.random() < 0.5:\n",
        "            return random.choice(synonyms[intent])\n",
        "    return command\n",
        "\n",
        "df['command_aug'] = df.apply(lambda x: augment_command(x['text'], x['label']), axis=1)\n",
        "\n",
        "# ==========================\n",
        "# TRAIN/VAL/TEST SPLIT\n",
        "# ==========================\n",
        "\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "# ==========================\n",
        "# TOKENIZATION & PADDING\n",
        "# ==========================\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_len = 20\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "# ==========================\n",
        "# LABEL ENCODING\n",
        "# ==========================\n",
        "le = LabelEncoder()\n",
        "y_train_enc = to_categorical(le.fit_transform(y_train))\n",
        "y_val_enc = to_categorical(le.transform(y_val))\n",
        "y_test_enc = to_categorical(le.transform(y_test))\n",
        "num_classes = y_train_enc.shape[1]\n",
        "\n",
        "# ==========================\n",
        "# BUILD REGULARIZED MULTI-LAYER MODEL\n",
        "# ==========================\n",
        "embedding_dim = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
        "model.add(SpatialDropout1D(0.5))  # embedding-level dropout\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# ==========================\n",
        "# TRAIN MODEL\n",
        "# ==========================\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train_enc,\n",
        "    validation_data=(X_val_pad, y_val_enc),\n",
        "    epochs=20,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# ==========================\n",
        "# EVALUATE\n",
        "# ==========================\n",
        "y_pred = model.predict(X_test_pad)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "y_test_classes = y_test_enc.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_test_classes, y_pred_classes, target_names=le.classes_))\n",
        "\n",
        "# ==========================\n",
        "# SAVE MODEL\n",
        "# ==========================\n",
        "model.save(\"/content/drive/MyDrive/voice_intent_model.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JdLPN35kHAuN",
        "outputId": "8ff5e318-5586-40b6-f773-001ab0e0a61f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                                               text        label language\n",
            "0                listen will you now give me a show   do_a_trick       en\n",
            "1          hey friend can you instantly flip around  turn_around       en\n",
            "2                  go1 could you quickly posture up        stand       en\n",
            "3              listen go1 can you for me about face  turn_around       en\n",
            "4  listen friend could you now go back about 6 step      go_back       en\n",
            "label\n",
            "do_a_trick     6250\n",
            "turn_around    6250\n",
            "stand          6250\n",
            "go_back        6250\n",
            "go_right       6250\n",
            "go_forward     6250\n",
            "sit            6250\n",
            "go_left        6250\n",
            "no_meaning     6250\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d_2             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_13                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_14                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d_2             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_13                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_14                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5600 - loss: 1.1078 - val_accuracy: 0.9976 - val_loss: 0.0119\n",
            "Epoch 2/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.9882 - loss: 0.0587 - val_accuracy: 0.9976 - val_loss: 0.0086\n",
            "Epoch 3/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.9935 - loss: 0.0315 - val_accuracy: 0.9988 - val_loss: 0.0034\n",
            "Epoch 4/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.9951 - loss: 0.0226 - val_accuracy: 0.9998 - val_loss: 7.3513e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9968 - loss: 0.0148 - val_accuracy: 0.9998 - val_loss: 8.6675e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.9986 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 1.6158e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.0084 - val_accuracy: 0.9999 - val_loss: 1.2299e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.9977 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 8.3687e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.9984 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 3.0776e-06\n",
            "Epoch 10/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 2.8038e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 1.8987e-07\n",
            "Epoch 12/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9989 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 3.8995e-08\n",
            "Epoch 13/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 7.1516e-06\n",
            "Epoch 14/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 5.8811e-08\n",
            "Epoch 15/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 1.1501e-08\n",
            "Epoch 16/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 2.9672e-10\n",
            "Epoch 17/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0050 - val_accuracy: 0.9998 - val_loss: 5.9633e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 4.8040e-10\n",
            "Epoch 19/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 1.0794e-08\n",
            "Epoch 20/20\n",
            "\u001b[1m1231/1231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 7.0647e-11\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  do_a_trick       1.00      1.00      1.00       937\n",
            "     go_back       1.00      1.00      1.00       937\n",
            "  go_forward       1.00      1.00      1.00       938\n",
            "     go_left       1.00      1.00      1.00       938\n",
            "    go_right       1.00      1.00      1.00       938\n",
            "  no_meaning       1.00      1.00      1.00       937\n",
            "         sit       1.00      1.00      1.00       938\n",
            "       stand       1.00      1.00      1.00       937\n",
            " turn_around       1.00      1.00      1.00       938\n",
            "\n",
            "    accuracy                           1.00      8438\n",
            "   macro avg       1.00      1.00      1.00      8438\n",
            "weighted avg       1.00      1.00      1.00      8438\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we save the model to use"
      ],
      "metadata": {
        "id": "IJj44Guu9E88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(le, f)"
      ],
      "metadata": {
        "id": "Xbb07gpaH6v3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we create an interavtive module to input text and it gives the probability corresponding for each intent."
      ],
      "metadata": {
        "id": "tSiH3DPY9Gyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "# ==========================\n",
        "# LOAD MODEL\n",
        "# ==========================\n",
        "model_path = \"/content/drive/MyDrive/voice_intent_model.keras\"\n",
        "model = load_model(model_path)\n",
        "\n",
        "# ==========================\n",
        "# LOAD TOKENIZER & LABEL ENCODER\n",
        "# ==========================\n",
        "# Make sure you saved them after training\n",
        "tokenizer_path = \"/content/drive/MyDrive/tokenizer.pkl\"\n",
        "label_encoder_path = \"/content/drive/MyDrive/label_encoder.pkl\"\n",
        "\n",
        "with open(tokenizer_path, \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "with open(label_encoder_path, \"rb\") as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "# ==========================\n",
        "# FUNCTION TO PREDICT INTENT PROBABILITIES\n",
        "# ==========================\n",
        "max_len = 20  # same as used during training\n",
        "\n",
        "def predict_intent(command):\n",
        "    seq = tokenizer.texts_to_sequences([command])\n",
        "    pad = pad_sequences(seq, maxlen=max_len, padding='post')\n",
        "    probs = model.predict(pad)[0]  # output probabilities\n",
        "    intent_probs = dict(zip(le.classes_, probs))\n",
        "    sorted_intents = dict(sorted(intent_probs.items(), key=lambda x: x[1], reverse=True))\n",
        "    return sorted_intents\n",
        "\n",
        "# ==========================\n",
        "# INTERACTIVE LOOP\n",
        "# ==========================\n",
        "while True:\n",
        "    command = input(\"Enter command (or 'quit' to exit): \")\n",
        "    if command.lower() == 'quit':\n",
        "        break\n",
        "    predictions = predict_intent(command)\n",
        "    print(\"\\nIntent probabilities:\")\n",
        "    for intent, prob in predictions.items():\n",
        "        print(f\"{intent}: {prob:.4f}\")\n",
        "    print(\"\\nMost likely intent:\", max(predictions, key=predictions.get))\n",
        "    print(\"=\"*40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czfYS3wsH9Nk",
        "outputId": "7c4fd22f-5f86-4b51-901b-4555e57c21f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter command (or 'quit' to exit): sleep\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "no_meaning: 1.0000\n",
            "do_a_trick: 0.0000\n",
            "turn_around: 0.0000\n",
            "stand: 0.0000\n",
            "go_right: 0.0000\n",
            "go_left: 0.0000\n",
            "sit: 0.0000\n",
            "go_back: 0.0000\n",
            "go_forward: 0.0000\n",
            "\n",
            "Most likely intent: no_meaning\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): rest\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "no_meaning: 1.0000\n",
            "sit: 0.0000\n",
            "go_right: 0.0000\n",
            "do_a_trick: 0.0000\n",
            "stand: 0.0000\n",
            "go_back: 0.0000\n",
            "turn_around: 0.0000\n",
            "go_left: 0.0000\n",
            "go_forward: 0.0000\n",
            "\n",
            "Most likely intent: no_meaning\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): lets walk\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "go_forward: 0.7068\n",
            "turn_around: 0.2686\n",
            "go_left: 0.0114\n",
            "go_right: 0.0077\n",
            "do_a_trick: 0.0034\n",
            "go_back: 0.0018\n",
            "stand: 0.0002\n",
            "no_meaning: 0.0000\n",
            "sit: 0.0000\n",
            "\n",
            "Most likely intent: go_forward\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): rest\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "no_meaning: 1.0000\n",
            "sit: 0.0000\n",
            "go_right: 0.0000\n",
            "do_a_trick: 0.0000\n",
            "stand: 0.0000\n",
            "go_back: 0.0000\n",
            "turn_around: 0.0000\n",
            "go_left: 0.0000\n",
            "go_forward: 0.0000\n",
            "\n",
            "Most likely intent: no_meaning\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): whats the color\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "no_meaning: 1.0000\n",
            "do_a_trick: 0.0000\n",
            "stand: 0.0000\n",
            "turn_around: 0.0000\n",
            "sit: 0.0000\n",
            "go_right: 0.0000\n",
            "go_left: 0.0000\n",
            "go_back: 0.0000\n",
            "go_forward: 0.0000\n",
            "\n",
            "Most likely intent: no_meaning\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): attack\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "no_meaning: 1.0000\n",
            "do_a_trick: 0.0000\n",
            "turn_around: 0.0000\n",
            "stand: 0.0000\n",
            "go_right: 0.0000\n",
            "go_left: 0.0000\n",
            "sit: 0.0000\n",
            "go_back: 0.0000\n",
            "go_forward: 0.0000\n",
            "\n",
            "Most likely intent: no_meaning\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): spin\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "do_a_trick: 0.9998\n",
            "turn_around: 0.0002\n",
            "no_meaning: 0.0000\n",
            "go_right: 0.0000\n",
            "go_forward: 0.0000\n",
            "sit: 0.0000\n",
            "stand: 0.0000\n",
            "go_left: 0.0000\n",
            "go_back: 0.0000\n",
            "\n",
            "Most likely intent: do_a_trick\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): flip\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "no_meaning: 0.5270\n",
            "do_a_trick: 0.4665\n",
            "turn_around: 0.0065\n",
            "go_right: 0.0000\n",
            "go_left: 0.0000\n",
            "stand: 0.0000\n",
            "go_forward: 0.0000\n",
            "sit: 0.0000\n",
            "go_back: 0.0000\n",
            "\n",
            "Most likely intent: no_meaning\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): dance\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "do_a_trick: 1.0000\n",
            "turn_around: 0.0000\n",
            "stand: 0.0000\n",
            "sit: 0.0000\n",
            "no_meaning: 0.0000\n",
            "go_forward: 0.0000\n",
            "go_right: 0.0000\n",
            "go_left: 0.0000\n",
            "go_back: 0.0000\n",
            "\n",
            "Most likely intent: do_a_trick\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): trot \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "no_meaning: 1.0000\n",
            "do_a_trick: 0.0000\n",
            "turn_around: 0.0000\n",
            "stand: 0.0000\n",
            "go_right: 0.0000\n",
            "go_left: 0.0000\n",
            "sit: 0.0000\n",
            "go_back: 0.0000\n",
            "go_forward: 0.0000\n",
            "\n",
            "Most likely intent: no_meaning\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): lets go\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "go_forward: 0.4536\n",
            "go_left: 0.2663\n",
            "turn_around: 0.1868\n",
            "go_right: 0.0746\n",
            "go_back: 0.0142\n",
            "do_a_trick: 0.0036\n",
            "no_meaning: 0.0006\n",
            "sit: 0.0002\n",
            "stand: 0.0002\n",
            "\n",
            "Most likely intent: go_forward\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): take a turn\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "do_a_trick: 0.9999\n",
            "turn_around: 0.0001\n",
            "no_meaning: 0.0000\n",
            "go_right: 0.0000\n",
            "go_forward: 0.0000\n",
            "sit: 0.0000\n",
            "stand: 0.0000\n",
            "go_left: 0.0000\n",
            "go_back: 0.0000\n",
            "\n",
            "Most likely intent: do_a_trick\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): turn around\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "turn_around: 1.0000\n",
            "go_forward: 0.0000\n",
            "do_a_trick: 0.0000\n",
            "go_right: 0.0000\n",
            "go_left: 0.0000\n",
            "stand: 0.0000\n",
            "go_back: 0.0000\n",
            "no_meaning: 0.0000\n",
            "sit: 0.0000\n",
            "\n",
            "Most likely intent: turn_around\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): jump up\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "stand: 1.0000\n",
            "no_meaning: 0.0000\n",
            "do_a_trick: 0.0000\n",
            "go_forward: 0.0000\n",
            "turn_around: 0.0000\n",
            "sit: 0.0000\n",
            "go_left: 0.0000\n",
            "go_back: 0.0000\n",
            "go_right: 0.0000\n",
            "\n",
            "Most likely intent: stand\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): lets jog together\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "Intent probabilities:\n",
            "do_a_trick: 0.9985\n",
            "turn_around: 0.0013\n",
            "no_meaning: 0.0001\n",
            "go_forward: 0.0001\n",
            "stand: 0.0000\n",
            "sit: 0.0000\n",
            "go_right: 0.0000\n",
            "go_left: 0.0000\n",
            "go_back: 0.0000\n",
            "\n",
            "Most likely intent: do_a_trick\n",
            "========================================\n",
            "Enter command (or 'quit' to exit): quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code uses softmax algorithim to train on the data. we tried playing with the hyper parameters to get the best results possible."
      ],
      "metadata": {
        "id": "Ss8-Zrdo9ZLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# IMPORTS\n",
        "# ==========================\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# ==========================\n",
        "# LOAD DATA\n",
        "# ==========================\n",
        "file_path = \"/content/drive/MyDrive/data/voice_commands_dataset_en_with_no_meaning.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(\"Dataset sample:\")\n",
        "print(df.head())\n",
        "\n",
        "# Ensure correct column names\n",
        "df = df.rename(columns={\"text\": \"command\", \"label\": \"intent\"})\n",
        "\n",
        "# Drop missing rows (just in case)\n",
        "df = df.dropna(subset=[\"command\", \"intent\"])\n",
        "\n",
        "# ==========================\n",
        "# TRAIN / VALIDATION / TEST SPLIT\n",
        "# ==========================\n",
        "X = df[\"command\"]\n",
        "y = df[\"intent\"]\n",
        "\n",
        "# Split into train, validation, and test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "# ==========================\n",
        "# TEXT VECTORIZATION (TF–IDF)\n",
        "# ==========================\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=30000,      # Limit vocab size\n",
        "    ngram_range=(1, 2),     # Unigrams + bigrams\n",
        "    stop_words='english'    # Remove common English words\n",
        ")\n",
        "\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_val_vec = vectorizer.transform(X_val)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"Vectorized shape:\", X_train_vec.shape)\n",
        "\n",
        "# ==========================\n",
        "# LABEL ENCODING\n",
        "# ==========================\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_val_enc = le.transform(y_val)\n",
        "y_test_enc = le.transform(y_test)\n",
        "\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Classes:\", list(le.classes_))\n",
        "\n",
        "# ==========================\n",
        "# MODEL: MULTINOMIAL LOGISTIC REGRESSION (SOFTMAX)\n",
        "# ==========================\n",
        "clf = LogisticRegression(\n",
        "    max_iter=10000,\n",
        "    solver='lbfgs',\n",
        "    multi_class='multinomial',  # enables softmax regression\n",
        "    C=2.0,                      # regularization strength (higher = less regularization)\n",
        ")\n",
        "\n",
        "# ==========================\n",
        "# TRAIN MODEL\n",
        "# ==========================\n",
        "clf.fit(X_train_vec, y_train_enc)\n",
        "\n",
        "# ==========================\n",
        "# VALIDATE MODEL\n",
        "# ==========================\n",
        "y_val_pred = clf.predict(X_val_vec)\n",
        "val_acc = accuracy_score(y_val_enc, y_val_pred)\n",
        "print(\"\\nValidation Accuracy:\", val_acc)\n",
        "print(\"\\nValidation Classification Report:\\n\")\n",
        "print(classification_report(y_val_enc, y_val_pred, target_names=le.classes_))\n",
        "\n",
        "# ==========================\n",
        "# TEST MODEL\n",
        "# ==========================\n",
        "y_test_pred = clf.predict(X_test_vec)\n",
        "test_acc = accuracy_score(y_test_enc, y_test_pred)\n",
        "print(\"\\n==========================\")\n",
        "print(\"📊 FINAL TEST PERFORMANCE\")\n",
        "print(\"==========================\")\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test_enc, y_test_pred, target_names=le.classes_))\n",
        "\n",
        "# ==========================\n",
        "# SAVE MODEL & VECTORIZER\n",
        "# ==========================\n",
        "import joblib\n",
        "joblib.dump(clf, \"/content/drive/MyDrive/voice_intent_softmax_model.pkl\")\n",
        "joblib.dump(vectorizer, \"/content/drive/MyDrive/voice_intent_tfidf_vectorizer.pkl\")\n",
        "joblib.dump(le, \"/content/drive/MyDrive/voice_intent_label_encoder.pkl\")\n",
        "\n",
        "print(\"\\n✅ Model, vectorizer, and label encoder saved successfully.\")\n"
      ],
      "metadata": {
        "id": "GCpikcncVWVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffa2f57-d14b-4880-c69c-d6b77719587d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sample:\n",
            "                                               text        label language\n",
            "0                listen will you now give me a show   do_a_trick       en\n",
            "1          hey friend can you instantly flip around  turn_around       en\n",
            "2                  go1 could you quickly posture up        stand       en\n",
            "3              listen go1 can you for me about face  turn_around       en\n",
            "4  listen friend could you now go back about 6 step      go_back       en\n",
            "Training samples: 39375, Validation: 8437, Test: 8438\n",
            "Vectorized shape: (39375, 1936)\n",
            "Classes: ['do_a_trick', 'go_back', 'go_forward', 'go_left', 'go_right', 'no_meaning', 'sit', 'stand', 'turn_around']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Accuracy: 0.968353680218087\n",
            "\n",
            "Validation Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  do_a_trick       0.90      0.89      0.90       938\n",
            "     go_back       0.96      0.94      0.95       938\n",
            "  go_forward       1.00      1.00      1.00       937\n",
            "     go_left       1.00      1.00      1.00       937\n",
            "    go_right       1.00      1.00      1.00       937\n",
            "  no_meaning       1.00      1.00      1.00       938\n",
            "         sit       0.99      0.96      0.98       937\n",
            "       stand       0.90      0.95      0.92       938\n",
            " turn_around       0.96      0.98      0.97       937\n",
            "\n",
            "    accuracy                           0.97      8437\n",
            "   macro avg       0.97      0.97      0.97      8437\n",
            "weighted avg       0.97      0.97      0.97      8437\n",
            "\n",
            "\n",
            "==========================\n",
            "📊 FINAL TEST PERFORMANCE\n",
            "==========================\n",
            "Test Accuracy: 0.9677648731926997\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  do_a_trick       0.91      0.89      0.90       937\n",
            "     go_back       0.95      0.93      0.94       937\n",
            "  go_forward       1.00      1.00      1.00       938\n",
            "     go_left       1.00      1.00      1.00       938\n",
            "    go_right       1.00      1.00      1.00       938\n",
            "  no_meaning       1.00      1.00      1.00       937\n",
            "         sit       0.99      0.96      0.98       938\n",
            "       stand       0.90      0.94      0.92       937\n",
            " turn_around       0.96      0.99      0.97       938\n",
            "\n",
            "    accuracy                           0.97      8438\n",
            "   macro avg       0.97      0.97      0.97      8438\n",
            "weighted avg       0.97      0.97      0.97      8438\n",
            "\n",
            "\n",
            "✅ Model, vectorizer, and label encoder saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its the same interactive module but to test the softmax algorithim."
      ],
      "metadata": {
        "id": "jnhBgI-X98Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# INTERACTIVE INFERENCE\n",
        "# ==========================\n",
        "import joblib\n",
        "from google.colab import output\n",
        "\n",
        "# Load saved model, vectorizer, and label encoder\n",
        "model_path = \"/content/drive/MyDrive/voice_intent_softmax_model.pkl\"\n",
        "vectorizer_path = \"/content/drive/MyDrive/voice_intent_tfidf_vectorizer.pkl\"\n",
        "label_encoder_path = \"/content/drive/MyDrive/voice_intent_label_encoder.pkl\"\n",
        "\n",
        "clf = joblib.load(model_path)\n",
        "vectorizer = joblib.load(vectorizer_path)\n",
        "le = joblib.load(label_encoder_path)\n",
        "\n",
        "# Interactive prediction loop\n",
        "def predict_intent():\n",
        "    while True:\n",
        "        text = input(\"\\n🎙️ Enter a command (or type 'exit' to quit): \").strip()\n",
        "        if text.lower() == 'exit':\n",
        "            print(\"👋 Exiting interactive mode.\")\n",
        "            break\n",
        "        if text == \"\":\n",
        "            print(\"⚠️ Please enter some text.\")\n",
        "            continue\n",
        "\n",
        "        # Transform text\n",
        "        text_vec = vectorizer.transform([text])\n",
        "        probs = clf.predict_proba(text_vec)[0]\n",
        "        pred_class = clf.predict(text_vec)[0]\n",
        "        intent = le.inverse_transform([pred_class])[0]\n",
        "\n",
        "        # Get top 3 probable intents\n",
        "        top_idx = probs.argsort()[-3:][::-1]\n",
        "        top_labels = le.inverse_transform(top_idx)\n",
        "        top_probs = probs[top_idx]\n",
        "\n",
        "        print(f\"\\n🔍 Predicted intent: **{intent.upper()}**\")\n",
        "        print(\"Top predictions:\")\n",
        "        for lbl, p in zip(top_labels, top_probs):\n",
        "            print(f\"  - {lbl:15s}: {p*100:.2f}%\")\n",
        "\n",
        "# Run interactive loop\n",
        "predict_intent()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbvS9lJal2j_",
        "outputId": "2809e5ef-edfd-44c9-eeef-ea4560f3544f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎙️ Enter a command (or type 'exit' to quit): dance\n",
            "\n",
            "🔍 Predicted intent: **DO_A_TRICK**\n",
            "Top predictions:\n",
            "  - do_a_trick     : 99.32%\n",
            "  - no_meaning     : 0.59%\n",
            "  - turn_around    : 0.02%\n",
            "\n",
            "🎙️ Enter a command (or type 'exit' to quit): flip\n",
            "\n",
            "🔍 Predicted intent: **TURN_AROUND**\n",
            "Top predictions:\n",
            "  - turn_around    : 95.90%\n",
            "  - do_a_trick     : 3.97%\n",
            "  - no_meaning     : 0.12%\n",
            "\n",
            "🎙️ Enter a command (or type 'exit' to quit): backflip \n",
            "\n",
            "🔍 Predicted intent: **NO_MEANING**\n",
            "Top predictions:\n",
            "  - no_meaning     : 85.99%\n",
            "  - go_back        : 3.05%\n",
            "  - do_a_trick     : 2.94%\n",
            "\n",
            "🎙️ Enter a command (or type 'exit' to quit): perform\n",
            "\n",
            "🔍 Predicted intent: **DO_A_TRICK**\n",
            "Top predictions:\n",
            "  - do_a_trick     : 89.52%\n",
            "  - no_meaning     : 7.42%\n",
            "  - go_back        : 0.69%\n",
            "\n",
            "🎙️ Enter a command (or type 'exit' to quit): lets walk\n",
            "\n",
            "🔍 Predicted intent: **NO_MEANING**\n",
            "Top predictions:\n",
            "  - no_meaning     : 65.80%\n",
            "  - go_back        : 22.23%\n",
            "  - go_forward     : 3.16%\n",
            "\n",
            "🎙️ Enter a command (or type 'exit' to quit): advance\n",
            "\n",
            "🔍 Predicted intent: **NO_MEANING**\n",
            "Top predictions:\n",
            "  - no_meaning     : 48.84%\n",
            "  - go_forward     : 44.80%\n",
            "  - go_back        : 1.25%\n",
            "\n",
            "🎙️ Enter a command (or type 'exit' to quit): go go\n",
            "\n",
            "🔍 Predicted intent: **NO_MEANING**\n",
            "Top predictions:\n",
            "  - no_meaning     : 85.99%\n",
            "  - go_back        : 3.05%\n",
            "  - do_a_trick     : 2.94%\n",
            "\n",
            "🎙️ Enter a command (or type 'exit' to quit): rest\n",
            "\n",
            "🔍 Predicted intent: **SIT**\n",
            "Top predictions:\n",
            "  - sit            : 99.82%\n",
            "  - no_meaning     : 0.16%\n",
            "  - turn_around    : 0.00%\n",
            "\n",
            "🎙️ Enter a command (or type 'exit' to quit): exit\n",
            "👋 Exiting interactive mode.\n"
          ]
        }
      ]
    }
  ]
}